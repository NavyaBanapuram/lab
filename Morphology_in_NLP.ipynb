{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGzRBndVTTQuM7BxHqPGgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasmin-lilly/jasmin-lilly/blob/main/Morphology_in_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Morphology in NLP\n",
        "**Morphology:**\n",
        "Morphology is the study of the internal structure of words.. Morphology focuses on how the components within a word (stems, root words, prefixes, suffixes, etc.) are arranged or modified to create different meanings.\n",
        "**Lemmatization :**\n",
        "Lemmatization is the process of reducing a word to its base form, or lemma, by analyzing its context and inflected form.\n"
      ],
      "metadata": {
        "id": "pWmclbp5oiM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "w7HmX-Npp84l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEYB1J2eqFsL",
        "outputId": "6762978e-8504-499e-e346-e219dbe63c8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def morphology_analysis(text):\n",
        "  words=word_tokenize(text)\n",
        "  stop_words=set(stopwords.words('english'))\n",
        "  words=[word for word in words if word.casefold() not in stop_words]\n",
        "  tagged_words=pos_tag(words)\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  lemmatized_words=[lemmatizer.lemmatize(word,get_wordnet_pos(pos)) for word,pos in tagged_words]\n",
        "  print(\"Original words:\",words)\n",
        "  print(\"Lemmatized words:\",lemmatized_words)\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "  if treebank_tag.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  elif treebank_tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif treebank_tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif treebank_tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return wordnet.NOUN\n",
        "\n",
        "  return lemmatized_words\n",
        "if __name__==\"__main__\":\n",
        "  text=input(\"Enter a text:\")\n",
        "  morphology_analysis(text)\n",
        "  for word,pos in pos_tag(word_tokenize(text)):\n",
        "    print(f\"Word:{word},POS Tag:{pos},WordNet POS Tag:{get_wordnet_pos(pos)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2H0eZb0wlVG",
        "outputId": "02755417-2045-4bee-a9ec-5a4b8ae3fadc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a text:Morphology is the study of the internal structure of words.. Morphology focuses on how the components within a word (stems, root words, prefixes, suffixes, etc.) are arranged or modified to create different meanings\n",
            "Original words: ['Morphology', 'study', 'internal', 'structure', 'words', '..', 'Morphology', 'focuses', 'components', 'within', 'word', '(', 'stems', ',', 'root', 'words', ',', 'prefixes', ',', 'suffixes', ',', 'etc', '.', ')', 'arranged', 'modified', 'create', 'different', 'meanings']\n",
            "Lemmatized words: ['Morphology', 'study', 'internal', 'structure', 'word', '..', 'Morphology', 'focus', 'component', 'within', 'word', '(', 'stem', ',', 'root', 'word', ',', 'prefix', ',', 'suffix', ',', 'etc', '.', ')', 'arrange', 'modified', 'create', 'different', 'meaning']\n",
            "Word:Morphology,POS Tag:NNP,WordNet POS Tag:n\n",
            "Word:is,POS Tag:VBZ,WordNet POS Tag:v\n",
            "Word:the,POS Tag:DT,WordNet POS Tag:n\n",
            "Word:study,POS Tag:NN,WordNet POS Tag:n\n",
            "Word:of,POS Tag:IN,WordNet POS Tag:n\n",
            "Word:the,POS Tag:DT,WordNet POS Tag:n\n",
            "Word:internal,POS Tag:JJ,WordNet POS Tag:a\n",
            "Word:structure,POS Tag:NN,WordNet POS Tag:n\n",
            "Word:of,POS Tag:IN,WordNet POS Tag:n\n",
            "Word:words,POS Tag:NNS,WordNet POS Tag:n\n",
            "Word:..,POS Tag:NNP,WordNet POS Tag:n\n",
            "Word:Morphology,POS Tag:NNP,WordNet POS Tag:n\n",
            "Word:focuses,POS Tag:VBZ,WordNet POS Tag:v\n",
            "Word:on,POS Tag:IN,WordNet POS Tag:n\n",
            "Word:how,POS Tag:WRB,WordNet POS Tag:n\n",
            "Word:the,POS Tag:DT,WordNet POS Tag:n\n",
            "Word:components,POS Tag:NNS,WordNet POS Tag:n\n",
            "Word:within,POS Tag:IN,WordNet POS Tag:n\n",
            "Word:a,POS Tag:DT,WordNet POS Tag:n\n",
            "Word:word,POS Tag:NN,WordNet POS Tag:n\n",
            "Word:(,POS Tag:(,WordNet POS Tag:n\n",
            "Word:stems,POS Tag:VBZ,WordNet POS Tag:v\n",
            "Word:,,POS Tag:,,WordNet POS Tag:n\n",
            "Word:root,POS Tag:NN,WordNet POS Tag:n\n",
            "Word:words,POS Tag:NNS,WordNet POS Tag:n\n",
            "Word:,,POS Tag:,,WordNet POS Tag:n\n",
            "Word:prefixes,POS Tag:NNS,WordNet POS Tag:n\n",
            "Word:,,POS Tag:,,WordNet POS Tag:n\n",
            "Word:suffixes,POS Tag:NNS,WordNet POS Tag:n\n",
            "Word:,,POS Tag:,,WordNet POS Tag:n\n",
            "Word:etc,POS Tag:FW,WordNet POS Tag:n\n",
            "Word:.,POS Tag:.,WordNet POS Tag:n\n",
            "Word:),POS Tag:),WordNet POS Tag:n\n",
            "Word:are,POS Tag:VBP,WordNet POS Tag:v\n",
            "Word:arranged,POS Tag:VBN,WordNet POS Tag:v\n",
            "Word:or,POS Tag:CC,WordNet POS Tag:n\n",
            "Word:modified,POS Tag:VBN,WordNet POS Tag:v\n",
            "Word:to,POS Tag:TO,WordNet POS Tag:n\n",
            "Word:create,POS Tag:VB,WordNet POS Tag:v\n",
            "Word:different,POS Tag:JJ,WordNet POS Tag:a\n",
            "Word:meanings,POS Tag:NNS,WordNet POS Tag:n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Articles are words like \"a,\" \"an,\" and \"the.\" They are used to specify whether a noun is singular or plural, and whether it is definite or indefinite."
      ],
      "metadata": {
        "id": "WMTMrWHGyB8G"
      }
    },
    {
      "source": [
        "articles = [\"a\", \"an\", \"the\"]\n",
        "\n",
        "def identify_articles(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    articles_in_text = [word for word in words if word.lower() in articles]\n",
        "    return articles_in_text\n",
        "\n",
        "example_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "articles_found = identify_articles(example_text)\n",
        "print(\"Articles found:\", articles_found)  # Output: ['The', 'the']"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMUTXCmHyFp_",
        "outputId": "697a50da-4873-4755-f2d7-98788a76b804"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Articles found: ['The', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepositions are words that show the relationship between a noun or pronoun and another word in the sentence. Examples include \"in,\" \"on,\" \"at,\" \"above,\" \"below,\" \"between,\" etc."
      ],
      "metadata": {
        "id": "95yIrpXvyKRO"
      }
    },
    {
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "def identify_prepositions(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    prepositions_in_text = [word for word, pos in tagged_words if pos == 'IN']\n",
        "    return prepositions_in_text\n",
        "\n",
        "example_text = \"The book is on the table.\"\n",
        "prepositions_found = identify_prepositions(example_text)\n",
        "print(\"Prepositions found:\", prepositions_found)  # Output: ['on']"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tYpFokIyPw-",
        "outputId": "6f2773f5-1b68-4062-a43e-93f3896c8064"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepositions found: ['on']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conjunctions are words that connect words, phrases, or clauses. Examples include \"and,\" \"but,\" \"or,\" \"so,\" \"because,\" etc."
      ],
      "metadata": {
        "id": "0eWOXZJOyU_G"
      }
    },
    {
      "source": [
        "def identify_conjunctions(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    conjunctions_in_text = [word for word, pos in tagged_words if pos in ['CC', 'IN']]  # CC for coordinating, IN for subordinating\n",
        "    return conjunctions_in_text\n",
        "\n",
        "example_text = \"I like apples and oranges, but I don't like bananas.\"\n",
        "conjunctions_found = identify_conjunctions(example_text)\n",
        "print(\"Conjunctions found:\", conjunctions_found)  # Output: ['and', 'but']"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSWMxrbkyZTu",
        "outputId": "51cc7656-85ec-48e6-c312-a00d0d641265"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunctions found: ['and', 'but']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interjections are words or phrases that express strong emotions or sudden feelings. Examples include \"Oh,\" \"Wow,\" \"Alas,\" \"Ouch,\" etc."
      ],
      "metadata": {
        "id": "4UNz4SGryc9O"
      }
    },
    {
      "source": [
        "import re\n",
        "\n",
        "def identify_interjections(text):\n",
        "    pattern = r\"\\b(?:oh|wow|alas|ouch|etc)\\b\"  # Add more interjections as needed\n",
        "    interjections_in_text = re.findall(pattern, text, re.IGNORECASE)\n",
        "    return interjections_in_text\n",
        "\n",
        "example_text = \"Wow! That's amazing!\"\n",
        "interjections_found = identify_interjections(example_text)\n",
        "print(\"Interjections found:\", interjections_found)  # Output: ['Wow']"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmgPB33oygkO",
        "outputId": "60b2cdd0-d3bd-428e-ba7a-7f229becb182"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interjections found: ['Wow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all types\n"
      ],
      "metadata": {
        "id": "SU1IMj3py7yn"
      }
    },
    {
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def identify_articles(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    articles_in_text = [word for word in words if word.lower() in [\"a\", \"an\", \"the\"]]\n",
        "    return articles_in_text\n",
        "\n",
        "def identify_prepositions(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    prepositions_in_text = [word for word, pos in tagged_words if pos == 'IN']\n",
        "    return prepositions_in_text\n",
        "\n",
        "def identify_conjunctions(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    conjunctions_in_text = [word for word, pos in tagged_words if pos in ['CC', 'IN']]\n",
        "    return conjunctions_in_text\n",
        "\n",
        "def identify_interjections(text):\n",
        "    pattern = r\"\\b(?:oh|wow|alas|ouch|etc)\\b\"  # Add more interjections as needed\n",
        "    interjections_in_text = re.findall(pattern, text, re.IGNORECASE)\n",
        "    return interjections_in_text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    text = input(\"Enter a text: \")\n",
        "\n",
        "    articles_found = identify_articles(text)\n",
        "    print(\"Articles found:\", articles_found)\n",
        "\n",
        "    prepositions_found = identify_prepositions(text)\n",
        "    print(\"Prepositions found:\", prepositions_found)\n",
        "\n",
        "    conjunctions_found = identify_conjunctions(text)\n",
        "    print(\"Conjunctions found:\", conjunctions_found)\n",
        "\n",
        "    interjections_found = identify_interjections(text)\n",
        "    print(\"Interjections found:\", interjections_found)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWU9CiV2yxPO",
        "outputId": "f648313d-9fb6-46a7-a7cc-89dce8fa04d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a text: wow wha abueaty?\n",
            "Articles found: []\n",
            "Prepositions found: []\n",
            "Conjunctions found: []\n",
            "Interjections found: ['wow']\n"
          ]
        }
      ]
    }
  ]
}