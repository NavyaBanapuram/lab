{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+XuHPVB0Y3LbJ4GxLW+vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasmin-lilly/jasmin-lilly/blob/main/Generating_words__in_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x344v9DCmqtF"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMu8gWGanNGq",
        "outputId": "3972e083-b1ee-4d2e-f7b1-f26e040f69fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_words(text,num_words):\n",
        "  words=word_tokenize(text)\n",
        "  stop_words=set(stopwords.words('english'))\n",
        "  words=[word for word in words if word.lower() not in stop_words]\n",
        "  generated_words=[]\n",
        "  for _ in range(num_words):\n",
        "    generated_words.append(random.choice(words))\n",
        "  return generated_words"
      ],
      "metadata": {
        "id": "vWuBXoCPps1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  text=\"Natural language prcessing (NLP) is \"\n",
        "  generated_words=generate_words(text,num_words=5)\n",
        "  print(\"Generated words:\",generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iisAnr0voGcL",
        "outputId": "f72b273f-711c-49d2-9053-f0f993154258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated words: ['Natural', ')', ')', 'language', 'prcessing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbATVpQ3qkHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generating words starts with \"n\" and also generated words are not duplicates"
      ],
      "metadata": {
        "id": "P11sm7Ggrkt9"
      }
    },
    {
      "source": [
        "def generate_words(text, num_words):\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.lower() not in stop_words and word.lower().startswith('n')]  # Filter words starting with 'n'\n",
        "    if len(words) < num_words:\n",
        "      num_words = len(words) # this makes sure that program works correctly even if num_words is greater than the number of available words.\n",
        "    generated_words = []\n",
        "    for _ in range(num_words):\n",
        "        if words:  # Check if there are any words starting with 'n'\n",
        "            generated_words.append(random.choice(words))\n",
        "        else:\n",
        "            break  # Stop if no words starting with 'n' are found\n",
        "    return generated_words"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "No730rs-qlLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  text=\"Natural language prcessing (NLP) is \"\n",
        "  generated_words=generate_words(text,num_words=5)\n",
        "  print(\"Generated words:\",generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSsmj-zCqoFq",
        "outputId": "3f119244-c6c8-45ee-bc71-13fa1026b9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated words: ['Natural', 'NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code to identify and correct spelling mistakes in the generated words."
      ],
      "metadata": {
        "id": "Iru3xxngsAqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker==0.7.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHFsG8misBoq",
        "outputId": "7d86b2f1-52ef-4b47-b641-728b92caf2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker==0.7.2\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "def generate_words(text, num_words):\n",
        "  words = word_tokenize(text)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "  spell = SpellChecker()\n",
        "  corrected_words = [spell.correction(word) for word in words]  # Correct spelling mistakes\n",
        "  corrected_words = [word for word in corrected_words if len(word) > 3] # Filter out short words\n",
        "  generated_words = []\n",
        "  for _ in range(num_words):\n",
        "    generated_words.append(random.choice(corrected_words))\n",
        "\n",
        "  return generated_words\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  text = \"Natural language prcessing (NLP) is \"\n",
        "  generated_words = generate_words(text, num_words=5)\n",
        "  print(\"Generated words:\", generated_words)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R1KJyM3sCSi",
        "outputId": "32c2f19f-0f76-4552-965d-52304787f301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated words: ['pressing', 'Natural', 'pressing', 'Natural', 'language']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "vo0RBm5-uxJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "allow the user to specify the starting letter for the generated words."
      ],
      "metadata": {
        "id": "VHE5tF-ut8RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_words(text, num_words, starting_letter):\n",
        "  words = word_tokenize(text)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [word for word in words if word.lower() not in stop_words and word.lower().startswith(starting_letter)]\n",
        "  generated_words = []\n",
        "  for _ in range(num_words):\n",
        "    if words:\n",
        "      generated_words.append(random.choice(words))\n",
        "    else:\n",
        "      break\n",
        "  return generated_words\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  text = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages.\"\n",
        "  starting_letter = input(\"Enter the starting letter: \").lower()  # Get input from user\n",
        "  num_words = 5  # Or get this as input as well\n",
        "  generated_words = generate_words(text, num_words, starting_letter)\n",
        "  print(\"Generated words:\", generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoiSLrHQuApZ",
        "outputId": "994a9b91-770f-4f38-c192-edcc20361314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the starting letter: a\n",
            "Generated words: ['artificial', 'artificial', 'artificial', 'artificial', 'artificial']\n"
          ]
        }
      ]
    }
  ]
}